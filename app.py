import streamlit as st
import feedparser
from datetime import datetime, timezone, timedelta
import pytz

# ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ í‚¤ì›Œë“œ & RSS ì†ŒìŠ¤
keywords = ['ê³ ìš©ë…¸ë™ë¶€', 'ë…¸ë™ë¶€', 'ê³ ìš©ë¶€']
rss_sources = {
    "ê²½í–¥ì‹ ë¬¸": "https://www.khan.co.kr/rss/rssdata/total_news.xml",
    "êµ­ë¯¼ì¼ë³´": "https://www.kmib.co.kr/rss/data/kmibRssAll.xml",
    "ë™ì•„ì¼ë³´": "https://rss.donga.com/total.xml",
    "ì„œìš¸ì‹ ë¬¸": "https://www.seoul.co.kr/xml/rss/rss_society.xml",
    "ì„¸ê³„ì¼ë³´": "http://rss.segye.com/segye_recent.xml",
    "ì•„ì‹œì•„íˆ¬ë°ì´": "http://www.asiatoday.co.kr/rss/01.xml",
    "ì¡°ì„ ì¼ë³´": "https://www.chosun.com/arc/outboundfeeds/rss/?outputType=xml",
    "í•œê²¨ë ˆ": "https://www.hani.co.kr/rss/",
    "ì´íˆ¬ë°ì´": "https://rss.etoday.co.kr/eto/etoday_news_all.xml",
    "í•œêµ­ì¼ë³´": "http://rss.hankooki.com/news/hk00_list.xml",
    "ë‰´ìŠ¤í† ë§ˆí† ": "https://www.newstomato.com/rss/",
    "ë¨¸ë‹ˆíˆ¬ë°ì´": "http://rss.mt.co.kr/mt_news.xml",
    "ë§¤ì¼ê²½ì œ": "https://www.mk.co.kr/rss/40300001/",
    "ë©”íŠ¸ë¡œê²½ì œ": "http://www.metroseoul.co.kr/rss/rss.xml",
    "ë¸Œë¦¿ì§€ê²½ì œ": "http://www.viva100.com/rss/rss.xml",
    "ì„œìš¸ê²½ì œ": "https://www.sedaily.com/rss/Feed.xml",
    "ì•„ì£¼ê²½ì œ": "http://www.ajunews.com/rss/news_all.xml",
    "ì´ë°ì¼ë¦¬": "http://rss.edaily.co.kr/edaily_news.xml",
    "ë§¤ì¼ë…¸ë™ë‰´ìŠ¤": "https://www.labortoday.co.kr/rss/allArticle.xml",
    "íŒŒì´ë‚¸ì…œë‰´ìŠ¤": "http://www.efnews.co.kr/rss/allArticle.xml",
    "í•œêµ­ê²½ì œ": "https://www.hankyung.com/feed/all-news",
    "ëŒ€í•œê²½ì œ": "http://www.dnews.co.kr/rss/rss.xml",
    "ì „ìì‹ ë¬¸": "http://rss.etnews.com/Section901.xml",
    "ì—°í•©ë‰´ìŠ¤": "https://www.yna.co.kr/rss/news.xml",
    "ë‰´ì‹œìŠ¤(ì†ë³´)": "https://www.newsis.com/RSS/sokbo.xml",
    "ë‰´ì‹œìŠ¤(ì‚¬íšŒ)": "https://www.newsis.com/RSS/society.xml",
    "ë‰´ì‹œìŠ¤(ì •ì¹˜)": "https://www.newsis.com/RSS/politics.xml",
    "ë‰´ìŠ¤1": "https://www.news1.kr/rss/news.xml"
}

# ğŸŒ ì„œìš¸ ê¸°ì¤€ ì‹œê°„ëŒ€ ì„¤ì •
kst = timezone(timedelta(hours=9))

# ğŸ“Œ Streamlit UI
st.title("ğŸ— ê³ ìš©ë…¸ë™ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° (RSS ê¸°ë°˜)")
st.markdown("ì§€ì •í•œ ì‹œê°„ëŒ€ì˜ RSS ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í‚¤ì›Œë“œì— ë§ëŠ” ê¸°ì‚¬ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.")

col1, col2 = st.columns(2)
with col1:
    start_time_input = st.time_input("â± ì‹œì‘ ì‹œê°„", value=datetime.now().time())
with col2:
    end_time_input = st.time_input("â± ì¢…ë£Œ ì‹œê°„", value=datetime.now().time())

if st.button("ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘"):
    today = datetime.now(tz=kst).date()
    start_time = datetime.combine(today, start_time_input).replace(tzinfo=kst)
    end_time = datetime.combine(today, end_time_input).replace(tzinfo=kst)

    filename = f"ê³ ìš©ë…¸ë™ë‰´ìŠ¤_{start_time.strftime('%Y%m%d_%H%M')}_to_{end_time.strftime('%H%M')}.txt"
    content_lines = []
    match_count = 0

    with st.spinner("ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
        for press, url in rss_sources.items():
            feed = feedparser.parse(url)
            for entry in feed.entries:
                title = entry.get("title", "")
                summary = entry.get("summary", "")
                published = entry.get("published_parsed")

                if published:
                    pub_time = datetime(*published[:6], tzinfo=timezone.utc).astimezone(kst)
                    if not (start_time <= pub_time <= end_time):
                        continue
                else:
                    pub_time = None

                if any(k in title for k in keywords) or any(k in summary for k in keywords):
                    line = f"[{press}] {title}\n{entry.link}\n"
                    line += f"ğŸ•’ {pub_time.strftime('%Y-%m-%d %H:%M:%S') if pub_time else 'ë°œí–‰ì‹œê°„ ì •ë³´ ì—†ìŒ'}\n\n"
                    content_lines.append(line)
                    match_count += 1

    if match_count > 0:
        result = "".join(content_lines)
        st.success(f"âœ… ì´ {match_count}ê±´ì˜ ë‰´ìŠ¤ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.download_button(label="ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=result, file_name=filename, mime="text/plain")
        st.text_area("ğŸ“ ë¯¸ë¦¬ë³´ê¸°", result, height=300)
    else:
        st.warning("âš ï¸ í•´ë‹¹ ì‹œê°„ëŒ€ì— ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
